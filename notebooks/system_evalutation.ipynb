{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fc17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spyder-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Claude suggested I add in the system path to help find the py module. See Appendix K. \n",
    "import sys\n",
    "sys.path.append('/Users/shoyou100/Visual-Code-Studio-workspace/assignment2-rag/src')\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import pandas as pd\n",
    "from naive_rag import NaiveRAG  \n",
    "from evaluation import Evaluation\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ab245",
   "metadata": {},
   "source": [
    "# Read Passages from the Datasets and Drop rows if they are NA or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0e11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uruguay (official full name in  ; pron.  , Eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is bordered by Brazil to the north, by Arge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montevideo was founded by the Spanish in the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The economy is largely based in agriculture (m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to Transparency International, Urugu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              passage\n",
       "id                                                   \n",
       "0   Uruguay (official full name in  ; pron.  , Eas...\n",
       "1   It is bordered by Brazil to the north, by Arge...\n",
       "2   Montevideo was founded by the Spanish in the e...\n",
       "3   The economy is largely based in agriculture (m...\n",
       "4   According to Transparency International, Urugu..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/passages.parquet/part.0.parquet\")\n",
    "\n",
    "print(passages.shape)\n",
    "passages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222f1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(918, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did his mother die of pneumonia?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When did Lincoln begin his political career?</td>\n",
       "      <td>1832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question     answer\n",
       "id                                                              \n",
       "0   Was Abraham Lincoln the sixteenth President of...        yes\n",
       "2   Did Lincoln sign the National Banking Act of 1...        yes\n",
       "4                    Did his mother die of pneumonia?         no\n",
       "6       How many long was Lincoln's formal education?  18 months\n",
       "8        When did Lincoln begin his political career?       1832"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/test.parquet/part.0.parquet\")\n",
    "print(queries.shape)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536601b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n",
      "Tokenizer loaded.\n",
      "Schema created.\n",
      "Seq2Seq model loaded.\n",
      "Milvus client connected.\n",
      "Dropping existing collection 'rag_mini'...\n",
      "Collection dropped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759542181.808160  805789 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "[[-0.00375673  0.03796374 -0.03182048 ... -0.04027529  0.00659006\n",
      "   0.03112675]\n",
      " [-0.03231501 -0.0094521  -0.10944731 ... -0.01333902 -0.0162666\n",
      "  -0.01005705]\n",
      " [ 0.00882224  0.0258874  -0.01894972 ... -0.03792767  0.07239034\n",
      "   0.00896565]\n",
      " ...\n",
      " [-0.00906186 -0.04410971 -0.11035763 ... -0.03789582  0.03106767\n",
      "   0.06000853]\n",
      " [ 0.02661895  0.05995833 -0.08694381 ...  0.0077695   0.01058571\n",
      "  -0.01678987]\n",
      " [-0.00681225  0.05897506 -0.05983922 ... -0.01872636 -0.01558293\n",
      "   0.01479083]]\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "naive_rag = NaiveRAG('all-MiniLM-L6-v2', 'google/flan-t5-small', 'rag_wikipedia_mini.db', 'rag_mini')\n",
    "\n",
    "passage_embeddings = naive_rag.embedding_model.encode(passages['passage'].tolist()) \n",
    "print(naive_rag.embedding_model.get_sentence_embedding_dimension())\n",
    "query_embeddings = naive_rag.embedding_model.encode(queries['question'].tolist())\n",
    "print(query_embeddings)\n",
    "print(naive_rag.embedding_model.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354e711",
   "metadata": {},
   "source": [
    "# Create Milvus Client and Insert your Embeddings to your DB\n",
    "- Make sure you define a schema for your collection (Points will be deducted if you fail to define a proper schema with ids, passage text, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c3a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns defined.\n",
      "Fields added to schema.\n",
      "Collection created.\n",
      "Data inserted successfully.\n",
      "Index created successfully.\n",
      "Collection loaded into memory\n"
     ]
    }
   ],
   "source": [
    "# Redefine id_ to ensure it is available\n",
    "id_ = passages.index.tolist()\n",
    "passage = passages['passage'].tolist()\n",
    "embedding = passage_embeddings.tolist()\n",
    "naive_rag.create_dataBase(passages, 'passage', passage_embeddings, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5d8681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity count: 3200\n",
      "Collection schema: {'collection_name': 'rag_mini', 'auto_id': False, 'num_shards': 0, 'description': '', 'fields': [{'field_id': 100, 'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'is_primary': True}, {'field_id': 101, 'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}], 'functions': [], 'aliases': [], 'collection_id': 0, 'consistency_level': 0, 'properties': {}, 'num_partitions': 0, 'enable_dynamic_field': True}\n"
     ]
    }
   ],
   "source": [
    "naive_rag.sanityCheck('rag_mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87920ab",
   "metadata": {},
   "source": [
    "# Steps to Fetch Results\n",
    "- Read the Question Dataset\n",
    "- Clean the Question Dataset if necessary (Drop Questions with NaN etc.)\n",
    "- Convert Each Query to a Vector Embedding (Use the same embedding model you used to embed your document)\n",
    "- Try for a Single Question First\n",
    "- Load Collection into Memory after creating Index for Search on your embedding field (This is an essential step before you can search in your db)\n",
    "- Search and Fetch Top N Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b68ab",
   "metadata": {},
   "source": [
    "**Develop your Prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023b43c",
   "metadata": {},
   "source": [
    "# Generate Responses for 100 queries in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc262ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['1832'], ['United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['yes'], ['yes'], ['Springfield'], ['1861'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['18'], ['1846'], ['1834'], ['New Salem'], ['yes'], ['yes'], ['Amedeo Avogadro'], ['a liceo'], ['1841'], ['1833'], ['yes'], ['yes'], ['no'], ['yes'], ['No, he was a king.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['He pressed for internal improvements and increased shipbuilding and foreign trade'], ['Anders Celsius'], ['a sailor'], ['When Avogadro announced'], ['no'], ['no'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['0'], ['Celsius was born in Uppsala in Sweden.'], ['No'], ['The Great Depression'], ['The book was published in 1745.'], ['yes'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['a wing'], ['a number of plants from the potato family (Solanaceae), such as nightshad'], ['yes'], ['no'], ['yes'], ['4'], ['During the sperm cell cycle'], ['biology'], ['yes'], ['no'], ['no'], ['ducks'], ['a cockchafer'], ['plants'], ['no'], ['no'], ['a molecule'], ['Coleopterists have formed organisations to facilitate the study of beetles. Among these'], ['Coleopterists have formed organizations to facilitate the study of beetles.'], ['It is a field of beetle biology.'], ['A single female lay from several dozen to several thousand eggs during her lifetime.'], ['no'], ['migration'], ['yes'], ['yes'], ['yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduated'], ['California'], ['the Supreme Court'], ['yes'], ['no'], ['no'], ['August 27, 1881'], ['New York City']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 1 - Instruction Prompt\n",
    "system_prompt = f\"You are a concise and accurate assistant. Answer the question based on the provided context.\"\n",
    "naive_rag.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "# Top-1 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row,1, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1b77e",
   "metadata": {},
   "source": [
    "# Finding out the Basic QA Metrics (F1 score, EM score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767cc301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 21/100 = 0.2100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_rag.calculateEM(queries.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ba1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.2413030303030303\n"
     ]
    }
   ],
   "source": [
    "# F1 Score Calculation\n",
    "evaluator = Evaluation()\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088c25b",
   "metadata": {},
   "source": [
    "# Persona Styles 2 & 3 - Top-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7272a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['1832'], ['United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['yes'], ['yes'], ['Springfield'], ['1861'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['1816'], ['1846'], ['one of the most respected and successful lawyers in Illinois and grew steadily more prosperous.'], ['New Salem'], ['yes'], ['yes'], ['Amedeo Avogadro'], ['john d. scott'], ['1841'], ['1833'], ['yes'], ['yes'], ['no'], ['yes'], ['He was a king of the Italian scientist.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['He also wanted to enhance and improve the commercial marine'], ['Anders Celsius'], ['a sailor'], ['1896'], ['no'], ['no'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['no'], ['Celsius was born in Uppsala in Sweden.'], ['no'], ['he was a professor of history at Columbia University Press'], ['Columbia University Press (New York, 2002) ISBN 0-231-13172-0'], ['a notorious pest of potato plants'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['wing'], ['suitable hosts can be a number of plants from the potato family (Solanaceae),'], ['a notorious pest of potato plants'], ['no'], ['yes'], ['4'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['Adult crawling water beetles use both their elytra and their hind co'], ['muskie'], ['a cockchafer'], ['plants from the potato family (Solanaceae), such as nightshade, tomato,'], ['no'], ['no'], ['a tube-like heart'], ['Coleopterists have formed organisations to facilitate the study of beetles. Among these'], ['coleopterists formed organisations to facilitate the study of beetles'], ['yes'], ['The larval period varies between species but can be as long as several years.'], ['no'], ['migration from neighbouring countries thousands of years ago'], ['yes'], ['yes'], ['no'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduate'], ['California'], ['john d. w. s. w. s. w.'], ['yes'], ['no'], ['yes'], ['August 27, 1881'], ['a slum']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 - Persona Prompt\n",
    "system_prompt = f\"You are a concise history teacher.\"\n",
    "\n",
    "naive_rag.queries_list = []  # Reset the queries list\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "\n",
    "# Top-1 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 1, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d1b9304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 20/100 = 0.2000\n",
      "F1 Score: 0.23759328579916816\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e21da63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no'], ['Yes'], ['no'], ['18 months'], ['1832'], ['the United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['no'], ['yes'], ['He believed that this would attract steamboat traffic, which would allow the sparsely populated'], ['Springfield, Illinois'], ['In 1891 Lincoln was appointed President of the United States.'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['1816'], ['1846'], ['a reputation as a formidable adversary during cross-examinations and in his closing'], ['New Salem'], ['Yes'], ['Yes'], ['Amedeo Avogadro'], ['he dedicated himself to the study of physics and mathematics (then called positive philosophy), and'], ['1841'], ['1833'], ['yes'], ['A noble ancient family of Piedmont, Italy.'], ['No'], ['yes'], ['Yes'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], [\"Reminiscent of Mach's principle, Tesla stated in 1925 that::\"], ['no'], ['He also wanted to enhance and improve the commercial marine .'], ['Anders Celsius'], ['Context: The name of the person who is named after him is \"Saya\"'], ['When announced'], ['yes'], ['no'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['Yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['The publisher of the book \"Marsden, Ben. Watt\\'s Perfect Engine\" was Columbia'], ['Context: \"Marsden, Ben. Watt\\'s Perfect Engine\" (Copenha'], ['yes'], ['Yes'], ['no'], ['sclerites'], ['Bright or contrasting colour patterns warn away potential predators'], ['Anthonomus grandis'], ['the developmental stages between each moult'], ['a wing'], ['suitable hosts can be a number of plants from the potato family (Solanaceae),'], ['yes'], ['no'], ['yes'], ['a total of .'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['Adult crawling water beetles use both their elytra and their hind co'], ['ducks'], ['A cockchafer with its elytra raised, exposing the membranous'], ['plants from the potato family (Solanaceae), such as nightshade, tomato,'], ['yes'], ['no'], ['the open circulatory system of the beetle is powered by a tube-like heart'], ['Yes'], ['Yes'], ['Yes'], ['The larval period varies between species but can be as long as several years.'], ['Yes'], ['The Archipelago Sea, between the Gulf of Bothnia and the Gulf of'], ['yes'], ['Yes'], ['Yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['He was an Amherst undergraduate'], ['California'], ['Chief Justice'], ['yes'], ['No'], ['no'], ['The relevant sentence in the passage is:'], ['John Calvin Coolidge, Sr.']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 - CoT\n",
    "system_prompt = f\"Read the question first. Then retrieve the context from the database. Finally, answer the question using the retrieved context.\"\n",
    "naive_rag.queries_list = []  # Reset the queries list\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "# Top-1 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 1, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7e45ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 19/100 = 0.1900\n",
      "F1 Score: 0.23487421427901306\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5b5a0",
   "metadata": {},
   "source": [
    "# Top-5 Retrieval with Embedding size 384 and 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e31799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['1832'], ['United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['yes'], ['yes'], ['Springfield'], ['1861'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['18'], ['1846'], ['1834'], ['New Salem'], ['yes'], ['yes'], ['Amedeo Avogadro'], ['a liceo'], ['1841'], ['1833'], ['yes'], ['yes'], ['no'], ['yes'], ['No, he was a king.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['He pressed for internal improvements and increased shipbuilding and foreign trade'], ['Anders Celsius'], ['a sailor'], ['When Avogadro announced'], ['no'], ['no'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['0'], ['Celsius was born in Uppsala in Sweden.'], ['No'], ['The Great Depression'], ['The book was published in 1745.'], ['yes'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['a wing'], ['a number of plants from the potato family (Solanaceae), such as nightshad'], ['yes'], ['no'], ['yes'], ['4'], ['During the sperm cell cycle'], ['biology'], ['yes'], ['no'], ['no'], ['ducks'], ['a cockchafer'], ['plants'], ['no'], ['no'], ['a molecule'], ['Coleopterists have formed organisations to facilitate the study of beetles. Among these'], ['Coleopterists have formed organizations to facilitate the study of beetles.'], ['It is a field of beetle biology.'], ['A single female lay from several dozen to several thousand eggs during her lifetime.'], ['no'], ['migration'], ['yes'], ['yes'], ['yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduated'], ['California'], ['the Supreme Court'], ['yes'], ['no'], ['no'], ['August 27, 1881'], ['New York City']]\n"
     ]
    }
   ],
   "source": [
    "# Top-5 Retrieval with Generation for 100 queries (Embedding size 384)\n",
    "system_prompt = f\"You are a concise and accurate assistant. Answer the question based on the provided context.\"\n",
    "naive_rag.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 5, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f0d91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 21/100 = 0.2100\n",
      "F1 Score: 0.23648141828501734\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 1 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d95e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['1832'], ['United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['yes'], ['yes'], ['Springfield'], ['1861'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['1816'], ['1846'], ['one of the most respected and successful lawyers in Illinois and grew steadily more prosperous.'], ['New Salem'], ['yes'], ['yes'], ['Amedeo Avogadro'], ['john d. scott'], ['1841'], ['1833'], ['yes'], ['yes'], ['no'], ['yes'], ['He was a king of the Italian scientist.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['He also wanted to enhance and improve the commercial marine'], ['Anders Celsius'], ['a sailor'], ['1896'], ['no'], ['no'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['no'], ['Celsius was born in Uppsala in Sweden.'], ['no'], ['he was a professor of history at Columbia University Press'], ['Columbia University Press (New York, 2002) ISBN 0-231-13172-0'], ['a notorious pest of potato plants'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['wing'], ['suitable hosts can be a number of plants from the potato family (Solanaceae),'], ['a notorious pest of potato plants'], ['no'], ['yes'], ['4'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['Adult crawling water beetles use both their elytra and their hind co'], ['muskie'], ['a cockchafer'], ['plants from the potato family (Solanaceae), such as nightshade, tomato,'], ['no'], ['no'], ['a tube-like heart'], ['Coleopterists have formed organisations to facilitate the study of beetles. Among these'], ['coleopterists formed organisations to facilitate the study of beetles'], ['yes'], ['The larval period varies between species but can be as long as several years.'], ['no'], ['migration from neighbouring countries thousands of years ago'], ['yes'], ['yes'], ['no'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduate'], ['California'], ['john d. w. s. w. s. w.'], ['yes'], ['no'], ['yes'], ['August 27, 1881'], ['a slum']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 - Persona Prompt\n",
    "system_prompt = f\"You are a concise history teacher.\"\n",
    "naive_rag.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for 100 queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 5, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d58b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 20/100 = 0.2000\n",
      "F1 Score: 0.23596184288707509\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "715b4efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no'], ['Yes'], ['no'], ['18 months'], ['1832'], ['the United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['no'], ['yes'], ['He believed that this would attract steamboat traffic, which would allow the sparsely populated'], ['Springfield, Illinois'], ['In 1891 Lincoln was appointed President of the United States.'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['1816'], ['1846'], ['a reputation as a formidable adversary during cross-examinations and in his closing'], ['New Salem'], ['Yes'], ['Yes'], ['Amedeo Avogadro'], ['he dedicated himself to the study of physics and mathematics (then called positive philosophy), and'], ['1841'], ['1833'], ['yes'], ['A noble ancient family of Piedmont, Italy.'], ['No'], ['yes'], ['Yes'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], [\"Reminiscent of Mach's principle, Tesla stated in 1925 that::\"], ['no'], ['He also wanted to enhance and improve the commercial marine .'], ['Anders Celsius'], ['Context: The name of the person who is named after him is \"Saya\"'], ['When announced'], ['yes'], ['no'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['Yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['The publisher of the book \"Marsden, Ben. Watt\\'s Perfect Engine\" was Columbia'], ['Context: \"Marsden, Ben. Watt\\'s Perfect Engine\" (Copenha'], ['yes'], ['Yes'], ['no'], ['sclerites'], ['Bright or contrasting colour patterns warn away potential predators'], ['Anthonomus grandis'], ['the developmental stages between each moult'], ['a wing'], ['suitable hosts can be a number of plants from the potato family (Solanaceae),'], ['yes'], ['no'], ['yes'], ['a total of .'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['Adult crawling water beetles use both their elytra and their hind co'], ['ducks'], ['A cockchafer with its elytra raised, exposing the membranous'], ['plants from the potato family (Solanaceae), such as nightshade, tomato,'], ['yes'], ['no'], ['the open circulatory system of the beetle is powered by a tube-like heart'], ['Yes'], ['Yes'], ['Yes'], ['The larval period varies between species but can be as long as several years.'], ['Yes'], ['The Archipelago Sea, between the Gulf of Bothnia and the Gulf of'], ['yes'], ['Yes'], ['Yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['He was an Amherst undergraduate'], ['California'], ['Chief Justice'], ['yes'], ['No'], ['no'], ['The relevant sentence in the passage is:'], ['John Calvin Coolidge, Sr.']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 - CoT\n",
    "system_prompt = f\"Read the question first. Then retrieve the context from the database. Finally, answer the question using the retrieved context.\"\n",
    "naive_rag.queries_list = []  # Reset the queries list\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for 100 queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 5,passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "973e7296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 19/100 = 0.1900\n",
      "F1 Score: 0.23487421427901306\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b21a9a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n",
      "Tokenizer loaded.\n",
      "Schema created.\n",
      "Seq2Seq model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus client connected.\n",
      "Dropping existing collection 'rag_mini_512'...\n",
      "Collection dropped.\n",
      "512\n",
      "[[-0.01053431  0.01283608 -0.04033115 ... -0.02846795  0.05243164\n",
      "  -0.01668956]\n",
      " [-0.0368097  -0.04185484 -0.0282476  ...  0.01714185  0.04274707\n",
      "  -0.02702508]\n",
      " [-0.00173918 -0.04569767  0.02886216 ...  0.01394532  0.01490885\n",
      "   0.03191647]\n",
      " ...\n",
      " [-0.05018368  0.01850008  0.02984808 ...  0.0090341  -0.05579572\n",
      "  -0.0622946 ]\n",
      " [-0.08829523 -0.05138754  0.0374678  ... -0.00082947 -0.045458\n",
      "  -0.03530771]\n",
      " [-0.06496639 -0.00691883 -0.06037014 ...  0.02557908 -0.04327128\n",
      "  -0.02709984]]\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Top-3 Retrieval for 100 queries (Embedding size 512)\n",
    "naive_rag2 = NaiveRAG('sentence-transformers/distiluse-base-multilingual-cased', 'google/flan-t5-small', 'rag_wikipedia_mini_512.db', 'rag_mini_512')\n",
    "passage_embeddings2 = naive_rag2.embedding_model.encode(passages['passage'].tolist()) \n",
    "print(naive_rag2.embedding_model.get_sentence_embedding_dimension())\n",
    "query_embeddings2 = naive_rag2.embedding_model.encode(queries['question'].tolist())\n",
    "print(query_embeddings2)\n",
    "print(naive_rag2.embedding_model.get_sentence_embedding_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ebf401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns defined.\n",
      "Fields added to schema.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created.\n",
      "Data inserted successfully.\n",
      "Index created successfully.\n",
      "Collection loaded into memory\n",
      "Entity count: 3200\n",
      "Collection schema: {'collection_name': 'rag_mini_512', 'auto_id': False, 'num_shards': 0, 'description': '', 'fields': [{'field_id': 100, 'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'is_primary': True}, {'field_id': 101, 'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 512}}], 'functions': [], 'aliases': [], 'collection_id': 0, 'consistency_level': 0, 'properties': {}, 'num_partitions': 0, 'enable_dynamic_field': True}\n"
     ]
    }
   ],
   "source": [
    "# Redefine id_ to ensure it is available\n",
    "id_ = passages.index.tolist()\n",
    "passage = passages['passage'].tolist()\n",
    "embedding = passage_embeddings2.tolist()\n",
    "naive_rag2.create_dataBase(passages, 'passage', passage_embeddings2, 512)\n",
    "\n",
    "# Entity count expected to be 6400 due to new rag_mini_512 db\n",
    "naive_rag2.sanityCheck('rag_mini_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88c6ee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['February 12, 1809 â April 15, 1865'], ['The legal tender act of 1862'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['no'], ['yes'], ['Perry County'], ['#He was the first President to coin an internationally recognized trademark, although not deliberately.'], ['Lincoln'], ['yes'], ['Michael Korda'], ['to preserve the Union'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['16'], ['1846'], ['23-year'], ['the eight judicial district'], ['yes'], ['no'], ['Amedeo Avogadro'], ['a liceo'], ['1884'], ['During the Second World War'], ['no'], ['yes'], ['no'], ['yes'], ['No, he was a king.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['Anders Celsius'], ['a sailor'], ['1928'], ['no'], ['yes'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['No'], ['Celsius was born in Uppsala in Sweden.'], ['No'], ['R\\xado de la Plata'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['yes'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['otters'], ['many beetles have eyes that are notched to some degree'], ['yes'], ['no'], ['yes'], ['4'], ['During the sperm cell cycle'], ['biology'], ['yes'], ['no'], ['no'], ['penguins'], ['a cockchafer'], ['beetles'], ['no'], ['no'], ['a molecule'], ['No, there is a thriving industry in the collection of beetle specimens for'], ['Coleopterists have formed organizations to facilitate the study of beetles.'], ['It is a field of beetle biology.'], ['A single female lay from several dozen to several thousand eggs during her lifetime.'], ['no'], ['They were able to survive.'], ['yes'], ['yes'], ['No'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduated'], ['Massachusetts'], ['the Supreme Court'], ['yes'], ['no'], ['no'], ['january 1, 1865'], ['Northampton']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 1 - Instruction Prompt\n",
    "system_prompt = f\"You are a concise and accurate assistant. Answer the question based on the provided context.\"\n",
    "naive_rag2.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag2.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag2.search(row, 5, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag2.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66f7bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 18/100 = 0.1800\n",
      "F1 Score: 0.23100906678460859\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 1 Evaluation\n",
    "naive_rag2.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag2.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd99fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['February 12, 1809 â April 15, 1865'], ['the legal rights of the public'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['no'], ['in a dispute with a shareholder, James A. Barret'], ['Perry County'], ['#He was the first President to coin an internationally recognized trademark, although not deliberately.'], ['a sailor'], ['yes'], ['Michael Korda'], ['to weaken the rebellion by destroying the economic base of its leadership class'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['sixteen'], ['1846'], ['23-year'], ['the eight judicial district'], ['yes'], ['no'], ['Amedeo Avogadro'], ['john d. scott'], ['1881'], ['he was born in 1891'], ['no'], ['yes'], ['no'], ['yes'], ['He was a king of the Italian scientist.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['Anders Celsius'], ['a sailor'], ['1928'], ['no'], ['yes'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['yes'], ['Celsius was born in Uppsala in Sweden.'], ['no'], ['R\\xado de la Plata'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['no'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['otters'], ['many beetles have eyes that are notched to some degree'], ['agricultural pests'], ['no'], ['yes'], ['4'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['whirligig beetles'], ['penguins'], ['a cockchafer'], ['beetles'], ['no'], ['no'], ['a molecule'], ['No'], ['coleopterists formed organisations to facilitate the study of beetles'], ['yes'], ['The larval period varies between species but can be as long as several years.'], ['no'], ['hardened shield like forewings'], ['yes'], ['yes'], ['No'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduate'], ['Massachusetts'], ['john d. w. s. w. s. w.'], ['yes'], ['No'], ['yes'], ['january 3'], ['Massachusetts']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 - Persona Prompt\n",
    "system_prompt = f\"You are a concise history teacher.\"\n",
    "\n",
    "naive_rag2.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag2.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag2.search(row, 5, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag2.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f7826ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 18/100 = 0.1800\n",
      "F1 Score: 0.22788798394158302\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 Evaluation\n",
    "naive_rag2.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag2.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41d5582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no'], ['Yes'], ['no'], ['18 months'], ['February 12, 1809 â April 15, 1865'], ['The Legal Tender Act of 1862'], ['Grace Bedell'], ['1789'], ['yes'], ['Yes'], ['no'], ['In one prominent 1851 case, he represented the Alton & Sangamon Railroad in'], ['Perry County'], ['#He was the first President to coin an internationally recognized trademark, although not deliberately.'], [':'], ['yes'], ['Michael Korda'], ['He made it clear that the North was fighting the war to preserve the Union, not to abolish slavery'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['16'], ['1846'], ['23-year'], ['the eight judicial district'], ['Yes'], ['no'], ['Amedeo Avogadro'], ['he dedicated himself to the study of physics and mathematics (then called positive philosophy), and'], ['1881'], ['He was born in the year of his birth.'], ['no'], ['A noble ancient family of Piedmont, Italy.'], ['No'], ['yes'], ['Yes'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], [\"Reminiscent of Mach's principle, Tesla stated in 1925 that::\"], ['no'], ['The Nile River at the ancient city of Aswan, a popular destination for vacationersE'], ['Anders Celsius'], ['a syringe'], ['In 1934'], ['no'], ['yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['R\\xado de la Plata in 1603.'], ['The Nile River at the ancient city of Aswan, a popular destination for vacationersE'], ['no'], ['Yes'], ['no'], ['sclerites'], ['Bright or contrasting colour patterns warn away potential predators'], ['Anthonomus grandis'], ['the developmental stages between each moult'], ['a case study on river otters'], ['The eyes are compound and may display remarkable adaptability'], ['Some species are agricultural pests, such as the Colorado potato beetle Leptino'], ['no'], ['yes'], ['a total of .'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['no'], ['Anhingas and cormorants'], ['A cockchafer with its elytra raised, exposing the membranous'], ['Beetles'], ['no'], ['no'], ['The Nile River'], ['Yes'], ['Yes'], ['Yes'], ['The larval period varies between species but can be as long as several years.'], ['Yes'], ['The name \"Coleoptera\" was given by Aristotle for the hardened shield'], ['Yes'], ['Yes'], ['Yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['He was an Amherst undergraduate'], ['Massachusetts'], ['Chief Justice'], ['yes'], ['Democrat'], ['no'], ['(7).'], ['Northampton']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 - CoT\n",
    "system_prompt = f\"Read the question first. Then retrieve the context from the database. Finally, answer the question using the retrieved context.\"\n",
    "naive_rag2.queries_list = []  # Reset the queries list\n",
    "naive_rag2.contexts_list = [] \n",
    "\n",
    "\n",
    "# Top-3 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag2.search(row, 5, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag2.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c07ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 17/100 = 0.1700\n",
      "F1 Score: 0.2245609239974565\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 Evaluation\n",
    "naive_rag2.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag2.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4fe1d",
   "metadata": {},
   "source": [
    "# Top 10 Retrieval with Embedding Sizes 384 and 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6941f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['1832'], ['United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['yes'], ['yes'], ['Springfield'], ['1861'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['18'], ['1846'], ['1834'], ['New Salem'], ['yes'], ['yes'], ['Amedeo Avogadro'], ['a liceo'], ['1841'], ['1833'], ['yes'], ['yes'], ['no'], ['yes'], ['No, he was a king.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['He pressed for internal improvements and increased shipbuilding and foreign trade'], ['Anders Celsius'], ['a sailor'], ['When Avogadro announced'], ['no'], ['no'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['0'], ['Celsius was born in Uppsala in Sweden.'], ['No'], ['The Great Depression'], ['The book was published in 1745.'], ['yes'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['a wing'], ['a number of plants from the potato family (Solanaceae), such as nightshad'], ['yes'], ['no'], ['yes'], ['4'], ['During the sperm cell cycle'], ['biology'], ['yes'], ['no'], ['no'], ['ducks'], ['a cockchafer'], ['plants'], ['no'], ['no'], ['a molecule'], ['Coleopterists have formed organisations to facilitate the study of beetles. Among these'], ['Coleopterists have formed organizations to facilitate the study of beetles.'], ['It is a field of beetle biology.'], ['A single female lay from several dozen to several thousand eggs during her lifetime.'], ['no'], ['migration'], ['yes'], ['yes'], ['yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduated'], ['California'], ['the Supreme Court'], ['yes'], ['no'], ['no'], ['August 27, 1881'], ['New York City']]\n"
     ]
    }
   ],
   "source": [
    "# Top-10 Retrieval with Generation for 100 queries (Embedding size 384)\n",
    "system_prompt = f\"You are a concise and accurate assistant. Answer the question based on the provided context.\"\n",
    "naive_rag.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 10, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9ad1e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 21/100 = 0.2100\n",
      "F1 Score: 0.2262351346280139\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 1 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cac480c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['1832'], ['United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['yes'], ['yes'], ['Springfield'], ['1861'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['1816'], ['1846'], ['one of the most respected and successful lawyers in Illinois and grew steadily more prosperous.'], ['New Salem'], ['yes'], ['yes'], ['Amedeo Avogadro'], ['john d. scott'], ['1841'], ['1833'], ['yes'], ['yes'], ['no'], ['yes'], ['He was a king of the Italian scientist.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['He also wanted to enhance and improve the commercial marine'], ['Anders Celsius'], ['a sailor'], ['1896'], ['no'], ['no'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['no'], ['Celsius was born in Uppsala in Sweden.'], ['no'], ['he was a professor of history at Columbia University Press'], ['Columbia University Press (New York, 2002) ISBN 0-231-13172-0'], ['a notorious pest of potato plants'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['wing'], ['suitable hosts can be a number of plants from the potato family (Solanaceae),'], ['a notorious pest of potato plants'], ['no'], ['yes'], ['4'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['Adult crawling water beetles use both their elytra and their hind co'], ['muskie'], ['a cockchafer'], ['plants from the potato family (Solanaceae), such as nightshade, tomato,'], ['no'], ['no'], ['a tube-like heart'], ['Coleopterists have formed organisations to facilitate the study of beetles. Among these'], ['coleopterists formed organisations to facilitate the study of beetles'], ['yes'], ['The larval period varies between species but can be as long as several years.'], ['no'], ['migration from neighbouring countries thousands of years ago'], ['yes'], ['yes'], ['no'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduate'], ['California'], ['john d. w. s. w. s. w.'], ['yes'], ['no'], ['yes'], ['August 27, 1881'], ['a slum']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 - Persona Prompt\n",
    "system_prompt = f\"You are a concise history teacher.\"\n",
    "naive_rag.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for 100 queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 10, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "871a0151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 20/100 = 0.2000\n",
      "F1 Score: 0.22693044432504045\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0048e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no'], ['Yes'], ['no'], ['18 months'], ['1832'], ['the United States Note'], ['Grace Bedell'], ['1789'], ['yes'], ['no'], ['yes'], ['He believed that this would attract steamboat traffic, which would allow the sparsely populated'], ['Springfield, Illinois'], ['In 1891 Lincoln was appointed President of the United States.'], ['Abraham Lincoln'], ['yes'], ['Ambrose Burnside'], ['freed slaves in territories not under Union control'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['1816'], ['1846'], ['a reputation as a formidable adversary during cross-examinations and in his closing'], ['New Salem'], ['Yes'], ['Yes'], ['Amedeo Avogadro'], ['he dedicated himself to the study of physics and mathematics (then called positive philosophy), and'], ['1841'], ['1833'], ['yes'], ['A noble ancient family of Piedmont, Italy.'], ['No'], ['yes'], ['Yes'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], [\"Reminiscent of Mach's principle, Tesla stated in 1925 that::\"], ['no'], ['He also wanted to enhance and improve the commercial marine .'], ['Anders Celsius'], ['Context: The name of the person who is named after him is \"Saya\"'], ['When announced'], ['yes'], ['no'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['Yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['The publisher of the book \"Marsden, Ben. Watt\\'s Perfect Engine\" was Columbia'], ['Context: \"Marsden, Ben. Watt\\'s Perfect Engine\" (Copenha'], ['yes'], ['Yes'], ['no'], ['sclerites'], ['Bright or contrasting colour patterns warn away potential predators'], ['Anthonomus grandis'], ['the developmental stages between each moult'], ['a wing'], ['suitable hosts can be a number of plants from the potato family (Solanaceae),'], ['yes'], ['no'], ['yes'], ['a total of .'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['Adult crawling water beetles use both their elytra and their hind co'], ['ducks'], ['A cockchafer with its elytra raised, exposing the membranous'], ['plants from the potato family (Solanaceae), such as nightshade, tomato,'], ['yes'], ['no'], ['the open circulatory system of the beetle is powered by a tube-like heart'], ['Yes'], ['Yes'], ['Yes'], ['The larval period varies between species but can be as long as several years.'], ['Yes'], ['The Archipelago Sea, between the Gulf of Bothnia and the Gulf of'], ['yes'], ['Yes'], ['Yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['He was an Amherst undergraduate'], ['California'], ['Chief Justice'], ['yes'], ['No'], ['no'], ['The relevant sentence in the passage is:'], ['John Calvin Coolidge, Sr.']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 - CoT\n",
    "system_prompt = f\"Read the question first. Then retrieve the context from the database. Finally, answer the question using the retrieved context.\"\n",
    "naive_rag.queries_list = []  # Reset the queries list\n",
    "naive_rag.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for 100 queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag.search(row, 10,passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69a5bf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 19/100 = 0.1900\n",
      "F1 Score: 0.22713924656784565\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 Evaluation\n",
    "naive_rag.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d340f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['February 12, 1809 â April 15, 1865'], ['The legal tender act of 1862'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['no'], ['yes'], ['Perry County'], ['#He was the first President to coin an internationally recognized trademark, although not deliberately.'], ['Lincoln'], ['yes'], ['Michael Korda'], ['to preserve the Union'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['16'], ['1846'], ['23-year'], ['the eight judicial district'], ['yes'], ['no'], ['Amedeo Avogadro'], ['a liceo'], ['1884'], ['During the Second World War'], ['no'], ['yes'], ['no'], ['yes'], ['No, he was a king.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['Anders Celsius'], ['a sailor'], ['1928'], ['no'], ['yes'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['No'], ['Celsius was born in Uppsala in Sweden.'], ['No'], ['R\\xado de la Plata'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['yes'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['otters'], ['many beetles have eyes that are notched to some degree'], ['yes'], ['no'], ['yes'], ['4'], ['During the sperm cell cycle'], ['biology'], ['yes'], ['no'], ['no'], ['penguins'], ['a cockchafer'], ['beetles'], ['no'], ['no'], ['a molecule'], ['No, there is a thriving industry in the collection of beetle specimens for'], ['Coleopterists have formed organizations to facilitate the study of beetles.'], ['It is a field of beetle biology.'], ['A single female lay from several dozen to several thousand eggs during her lifetime.'], ['no'], ['They were able to survive.'], ['yes'], ['yes'], ['No'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduated'], ['Massachusetts'], ['the Supreme Court'], ['yes'], ['no'], ['no'], ['january 1, 1865'], ['Northampton']]\n"
     ]
    }
   ],
   "source": [
    "# Top-10 Retrieval for 100 queries (Embedding size 512)\n",
    "# Prompt Style 1 - Instruction Prompt\n",
    "system_prompt = f\"You are a concise and accurate assistant. Answer the question based on the provided context.\"\n",
    "naive_rag2.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag2.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag2.search(row, 10, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag2.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bcdfcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 18/100 = 0.1800\n",
      "F1 Score: 0.22565301081787148\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 1 Evaluation\n",
    "naive_rag2.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag2.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea420205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['yes'], ['yes'], ['no'], ['18 months'], ['February 12, 1809 â April 15, 1865'], ['the legal rights of the public'], ['Grace Bedell'], ['1789'], ['yes'], ['yes'], ['no'], ['in a dispute with a shareholder, James A. Barret'], ['Perry County'], ['#He was the first President to coin an internationally recognized trademark, although not deliberately.'], ['a sailor'], ['yes'], ['Michael Korda'], ['to weaken the rebellion by destroying the economic base of its leadership class'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['sixteen'], ['1846'], ['23-year'], ['the eight judicial district'], ['yes'], ['no'], ['Amedeo Avogadro'], ['john d. scott'], ['1881'], ['he was born in 1891'], ['no'], ['yes'], ['no'], ['yes'], ['He was a king of the Italian scientist.'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], ['Tesla stated in 1925 that::'], ['no'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['Anders Celsius'], ['a sailor'], ['1928'], ['no'], ['yes'], ['yes'], ['yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['yes'], ['Celsius was born in Uppsala in Sweden.'], ['no'], ['R\\xado de la Plata'], ['The completion of the Aswan High Dam in 1971 and the resultant Lake Nasser have altered'], ['no'], ['no'], ['no'], ['sclerites'], ['aposematism'], ['Anthonomus grandis'], ['instars'], ['otters'], ['many beetles have eyes that are notched to some degree'], ['agricultural pests'], ['no'], ['yes'], ['4'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['whirligig beetles'], ['penguins'], ['a cockchafer'], ['beetles'], ['no'], ['no'], ['a molecule'], ['No'], ['coleopterists formed organisations to facilitate the study of beetles'], ['yes'], ['The larval period varies between species but can be as long as several years.'], ['no'], ['hardened shield like forewings'], ['yes'], ['yes'], ['No'], ['1765'], ['1905'], ['Roaring Twenties'], ['graduate'], ['Massachusetts'], ['john d. w. s. w. s. w.'], ['yes'], ['No'], ['yes'], ['january 3'], ['Massachusetts']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 - Persona Prompt\n",
    "system_prompt = f\"You are a concise history teacher.\"\n",
    "\n",
    "naive_rag2.queries_list = []  # Reset queries_list before new searches\n",
    "naive_rag2.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag2.search(row, 10, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag2.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cbab3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 18/100 = 0.1800\n",
      "F1 Score: 0.22425211033376669\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 2 Evaluation\n",
    "naive_rag2.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag2.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a78d87ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['no'], ['Yes'], ['no'], ['18 months'], ['February 12, 1809 â April 15, 1865'], ['The Legal Tender Act of 1862'], ['Grace Bedell'], ['1789'], ['yes'], ['Yes'], ['no'], ['In one prominent 1851 case, he represented the Alton & Sangamon Railroad in'], ['Perry County'], ['#He was the first President to coin an internationally recognized trademark, although not deliberately.'], [':'], ['yes'], ['Michael Korda'], ['He made it clear that the North was fighting the war to preserve the Union, not to abolish slavery'], ['yes'], ['yes'], ['Lincoln was eventually chosen as the Republican candidate for the 1860 election for several reasons.'], ['16'], ['1846'], ['23-year'], ['the eight judicial district'], ['Yes'], ['no'], ['Amedeo Avogadro'], ['he dedicated himself to the study of physics and mathematics (then called positive philosophy), and'], ['1881'], ['He was born in the year of his birth.'], ['no'], ['A noble ancient family of Piedmont, Italy.'], ['No'], ['yes'], ['Yes'], [\"Avogadro 's number is commonly used to compute the results of chemical reactions\"], [\"Reminiscent of Mach's principle, Tesla stated in 1925 that::\"], ['no'], ['The Nile River at the ancient city of Aswan, a popular destination for vacationersE'], ['Anders Celsius'], ['a syringe'], ['In 1934'], ['no'], ['yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['yes'], ['Anders Celsius'], ['named after him'], ['The Celsius crater on the Moon is named after him.'], ['yes'], ['He was professor of astronomy at Uppsala University from 1730 to 1744'], ['Yes'], ['R\\xado de la Plata in 1603.'], ['The Nile River at the ancient city of Aswan, a popular destination for vacationersE'], ['no'], ['Yes'], ['no'], ['sclerites'], ['Bright or contrasting colour patterns warn away potential predators'], ['Anthonomus grandis'], ['the developmental stages between each moult'], ['a case study on river otters'], ['The eyes are compound and may display remarkable adaptability'], ['Some species are agricultural pests, such as the Colorado potato beetle Leptino'], ['no'], ['yes'], ['a total of .'], ['laying their eggs'], ['coleopterology'], ['yes'], ['no'], ['no'], ['Anhingas and cormorants'], ['A cockchafer with its elytra raised, exposing the membranous'], ['Beetles'], ['no'], ['no'], ['The Nile River'], ['Yes'], ['Yes'], ['Yes'], ['The larval period varies between species but can be as long as several years.'], ['Yes'], ['The name \"Coleoptera\" was given by Aristotle for the hardened shield'], ['Yes'], ['Yes'], ['Yes'], ['1765'], ['1905'], ['Roaring Twenties'], ['He was an Amherst undergraduate'], ['Massachusetts'], ['Chief Justice'], ['yes'], ['Democrat'], ['no'], ['(7).'], ['Northampton']]\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 - CoT\n",
    "system_prompt = f\"Read the question first. Then retrieve the context from the database. Finally, answer the question using the retrieved context.\"\n",
    "naive_rag2.queries_list = []  # Reset the queries list\n",
    "naive_rag2.contexts_list = [] \n",
    "\n",
    "# Top-3 Retrieval with Generation for all queries\n",
    "count = 0\n",
    "for row in queries.question:\n",
    "   naive_rag2.search(row, 10, passage, system_prompt)\n",
    "   count += 1\n",
    "   if count == 100:\n",
    "      break\n",
    "\n",
    "print(naive_rag2.queries_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e83e76ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Score: 17/100 = 0.1700\n",
      "F1 Score: 0.22249826594114522\n"
     ]
    }
   ],
   "source": [
    "# Prompt Style 3 Evaluation\n",
    "naive_rag2.calculateEM(queries.answer)\n",
    "f1_score = evaluator.compute_f1(naive_rag2.flatten_answer, queries.answer.tolist())\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef21cbf",
   "metadata": {},
   "source": [
    "# Advanced Evaluation using RAGAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46e75b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude code helped provide the structure for the data and for the evaluation code below. See Appendix S.\n",
    "data = {\n",
    "    \"question\": queries.question[:100].tolist() ,                     # Question\n",
    "    \"answer\": naive_rag.flatten_answer ,                       # Generated Answer\n",
    "    \"contexts\": naive_rag.contexts_list ,                     # Context you pass in. You can just use top-1 here\n",
    "    \"reference\": [truth for truth in queries.answer[:100].tolist()]                  # Reference Answer in the dataset (Human annotated)\n",
    "}\n",
    "\n",
    "# Convert dict to dataset\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32f0a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759542404.521797  805789 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759542404.551809  805789 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "E0000 00:00:1759542404.556713  805789 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "/var/folders/f0/3bfdym850v72lx6m176k5jk80000gn/T/ipykernel_64788/3640797945.py:14: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  gemini_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
      "Evaluating:   0%|          | 0/400 [00:00<?, ?it/s]E0000 00:00:1759542404.974720  805789 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "Exception raised in Job[1]: IndexError(list index out of range)\n",
      "Exception raised in Job[9]: IndexError(list index out of range)\n",
      "Evaluating:   0%|          | 1/400 [00:01<07:45,  1.17s/it]Exception raised in Job[5]: IndexError(list index out of range)\n",
      "Exception raised in Job[13]: IndexError(list index out of range)\n",
      "Evaluating:   3%|▎         | 13/400 [00:07<03:00,  2.15it/s]Exception raised in Job[21]: IndexError(list index out of range)\n",
      "Evaluating:   4%|▎         | 14/400 [00:10<05:08,  1.25it/s]Exception raised in Job[25]: IndexError(list index out of range)\n",
      "Evaluating:   6%|▌         | 22/400 [00:11<02:46,  2.27it/s]Exception raised in Job[29]: IndexError(list index out of range)\n",
      "Evaluating:   6%|▋         | 26/400 [00:13<02:51,  2.18it/s]Exception raised in Job[37]: IndexError(list index out of range)\n",
      "Exception raised in Job[33]: IndexError(list index out of range)\n",
      "Evaluating:  10%|▉         | 38/400 [00:18<02:32,  2.37it/s]Exception raised in Job[49]: IndexError(list index out of range)\n",
      "Evaluating:  10%|█         | 40/400 [00:24<04:58,  1.21it/s]Exception raised in Job[53]: IndexError(list index out of range)\n",
      "Evaluating:  16%|█▋        | 66/400 [00:40<04:49,  1.15it/s]Exception raised in Job[77]: IndexError(list index out of range)\n",
      "Evaluating:  22%|██▏       | 89/400 [00:50<02:38,  1.96it/s]Exception raised in Job[101]: IndexError(list index out of range)\n",
      "Evaluating:  26%|██▋       | 106/400 [01:05<03:36,  1.36it/s]Exception raised in Job[117]: IndexError(list index out of range)\n",
      "Evaluating:  28%|██▊       | 113/400 [01:07<02:56,  1.63it/s]Exception raised in Job[121]: IndexError(list index out of range)\n",
      "Exception raised in Job[125]: IndexError(list index out of range)\n",
      "Evaluating:  30%|███       | 120/400 [01:09<02:05,  2.23it/s]Exception raised in Job[133]: IndexError(list index out of range)\n",
      "Exception raised in Job[129]: IndexError(list index out of range)\n",
      "Evaluating:  32%|███▏      | 126/400 [01:12<02:01,  2.26it/s]Exception raised in Job[137]: IndexError(list index out of range)\n",
      "Evaluating:  33%|███▎      | 132/400 [01:14<01:48,  2.46it/s]Exception raised in Job[141]: IndexError(list index out of range)\n",
      "Evaluating:  34%|███▍      | 138/400 [01:16<01:34,  2.78it/s]Exception raised in Job[145]: IndexError(list index out of range)\n",
      "Exception raised in Job[149]: IndexError(list index out of range)\n",
      "Evaluating:  39%|███▉      | 155/400 [01:23<01:39,  2.45it/s]Exception raised in Job[161]: IndexError(list index out of range)\n",
      "Evaluating:  41%|████▏     | 165/400 [01:29<02:08,  1.83it/s]Exception raised in Job[173]: IndexError(list index out of range)\n",
      "Evaluating:  42%|████▏     | 168/400 [01:32<02:21,  1.64it/s]Exception raised in Job[177]: IndexError(list index out of range)\n",
      "Evaluating:  44%|████▎     | 174/400 [01:33<01:43,  2.18it/s]Exception raised in Job[185]: IndexError(list index out of range)\n",
      "Exception raised in Job[181]: IndexError(list index out of range)\n",
      "Evaluating:  50%|████▉     | 198/400 [01:49<02:49,  1.19it/s]Exception raised in Job[209]: IndexError(list index out of range)\n",
      "Evaluating:  51%|█████     | 204/400 [01:51<01:56,  1.68it/s]Exception raised in Job[213]: IndexError(list index out of range)\n",
      "Exception raised in Job[217]: IndexError(list index out of range)\n",
      "Evaluating:  54%|█████▍    | 216/400 [01:54<01:04,  2.85it/s]Exception raised in Job[221]: IndexError(list index out of range)\n",
      "Evaluating:  54%|█████▍    | 217/400 [01:55<01:14,  2.44it/s]Exception raised in Job[229]: IndexError(list index out of range)\n",
      "Evaluating:  55%|█████▌    | 220/400 [01:56<01:17,  2.31it/s]Exception raised in Job[225]: IndexError(list index out of range)\n",
      "Evaluating:  57%|█████▋    | 229/400 [01:59<00:52,  3.23it/s]Exception raised in Job[237]: IndexError(list index out of range)\n",
      "Evaluating:  58%|█████▊    | 231/400 [02:01<01:15,  2.25it/s]Exception raised in Job[241]: IndexError(list index out of range)\n",
      "Evaluating:  66%|██████▋   | 265/400 [02:22<01:18,  1.72it/s]Exception raised in Job[273]: IndexError(list index out of range)\n",
      "Exception raised in Job[277]: IndexError(list index out of range)\n",
      "Evaluating:  73%|███████▎  | 292/400 [02:35<00:48,  2.21it/s]Exception raised in Job[305]: IndexError(list index out of range)\n",
      "Exception raised in Job[301]: IndexError(list index out of range)\n",
      "Exception raised in Job[297]: IndexError(list index out of range)\n",
      "Evaluating:  79%|███████▉  | 316/400 [02:50<00:43,  1.94it/s]Exception raised in Job[329]: IndexError(list index out of range)\n",
      "Evaluating:  79%|███████▉  | 317/400 [02:51<00:48,  1.71it/s]Exception raised in Job[325]: IndexError(list index out of range)\n",
      "Exception raised in Job[321]: IndexError(list index out of range)\n",
      "Evaluating:  84%|████████▍ | 336/400 [02:59<00:27,  2.29it/s]Exception raised in Job[341]: IndexError(list index out of range)\n",
      "Exception raised in Job[349]: IndexError(list index out of range)\n",
      "Exception raised in Job[345]: IndexError(list index out of range)\n",
      "Evaluating:  84%|████████▍ | 337/400 [03:03<00:47,  1.33it/s]Exception raised in Job[357]: IndexError(list index out of range)\n",
      "Exception raised in Job[361]: IndexError(list index out of range)\n",
      "Evaluating:  88%|████████▊ | 351/400 [03:06<00:18,  2.66it/s]Exception raised in Job[353]: IndexError(list index out of range)\n",
      "Evaluating:  88%|████████▊ | 352/400 [03:09<00:29,  1.63it/s]Exception raised in Job[365]: IndexError(list index out of range)\n",
      "Evaluating:  92%|█████████▏| 366/400 [03:11<00:10,  3.23it/s]Exception raised in Job[369]: IndexError(list index out of range)\n",
      "Exception raised in Job[377]: IndexError(list index out of range)\n",
      "Evaluating:  93%|█████████▎| 372/400 [03:14<00:09,  2.80it/s]Exception raised in Job[373]: IndexError(list index out of range)\n",
      "Evaluating:  94%|█████████▎| 374/400 [03:15<00:10,  2.55it/s]Exception raised in Job[381]: IndexError(list index out of range)\n",
      "Exception raised in Job[385]: IndexError(list index out of range)\n",
      "Evaluating:  96%|█████████▋| 386/400 [03:18<00:03,  3.81it/s]Exception raised in Job[393]: IndexError(list index out of range)\n",
      "Exception raised in Job[389]: IndexError(list index out of range)\n",
      "Evaluating:  97%|█████████▋| 388/400 [03:21<00:05,  2.11it/s]Exception raised in Job[397]: IndexError(list index out of range)\n",
      "Evaluating: 100%|██████████| 400/400 [03:23<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGAs Evaluation Results:\n",
      "{'faithfulness': 0.4823, 'answer_relevancy': 0.7384, 'context_recall': 0.4100, 'context_precision': 0.3700}\n"
     ]
    }
   ],
   "source": [
    "# Pass the dataset above to the evaluate method in RAGAs\n",
    "# Your code here\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0))\n",
    "gemini_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate using Gemini\n",
    "results = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "    ],\n",
    "    llm=gemini_llm,\n",
    "    embeddings=gemini_embeddings,\n",
    ")\n",
    "\n",
    "print(\"RAGAs Evaluation Results:\")\n",
    "print(results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
